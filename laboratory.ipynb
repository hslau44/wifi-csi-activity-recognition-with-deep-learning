{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S 0.0 Set parameter and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler, MinMaxScaler,Normalizer\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset,models,utils\n",
    "from external.yousefi import dataset as external_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters \n",
    "INPUT_SHAPE = (1000,90,1) \n",
    "ACTIVATION = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function define\n",
    "lrelu = tf.keras.layers.LeakyReLU\n",
    "softmax = tf.keras.layers.Softmax\n",
    "normalization = tfa.layers.InstanceNormalization\n",
    "identity = tf.keras.layers.Lambda(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient reverse layer (Yanin 2015)\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GradReverseLayer, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    inputs  = tf.keras.layers.InputLayer((1000,90,1))\n",
    "    # Layer 1\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides = (5,5))\n",
    "    norm_1 = tfa.layers.InstanceNormalization(axis=3,center=True,scale=True,beta_initializer=\"random_uniform\",gamma_initializer=\"random_uniform\")\n",
    "    actv_1 = tf.keras.layers.ReLU()\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    # Layer 2\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (3,3))\n",
    "    norm_2 = tfa.layers.InstanceNormalization(axis=3,center=True,scale=True,beta_initializer=\"random_uniform\",gamma_initializer=\"random_uniform\")\n",
    "    actv_2 = tf.keras.layers.ReLU()\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    # Layer 3\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(2,2), strides = (2,2))\n",
    "    norm_3 = tfa.layers.InstanceNormalization(axis=3,center=True,scale=True,beta_initializer=\"random_uniform\",gamma_initializer=\"random_uniform\")\n",
    "    actv_3 = tf.keras.layers.Activation('tanh')\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    # Latent output\n",
    "    latent = tf.keras.layers.Flatten()\n",
    "    \n",
    "    # model define\n",
    "    mdl = tf.keras.models.Sequential([\n",
    "        inputs,conv_1,norm_1,actv_1,pool_1,\n",
    "        conv_2,norm_2,actv_2,pool_2,\n",
    "        conv_3,norm_3,actv_3,pool_3,latent\n",
    "    ])\n",
    "\n",
    "    return mdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(latent_shape,output_shape):\n",
    "    \n",
    "    inputs  = tf.keras.layers.InputLayer(latent_shape)\n",
    "    dense_1 = tf.keras.layers.Dense(128)\n",
    "    actv_1  = tf.keras.layers.LeakyReLU()\n",
    "    dense_2 = tf.keras.layers.Dense(output_shape)\n",
    "    actv_2  = tf.keras.layers.Softmax()\n",
    "    \n",
    "    mdl = tf.keras.models.Sequential([inputs,dense_1,actv_1,dense_2,actv_2])\n",
    "    return mdl\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VGG(num=8,top=True):\n",
    "    base_model = VGG16(include_top=False,input_shape=(1000, 90, 3))\n",
    "    base_model.trainable = False\n",
    "    inputs = tf.keras.layers.Input(shape=(1000, 90, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    p = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if top == True:\n",
    "        p = tf.keras.layers.Dense(128,activation='relu')(p)\n",
    "        outputs = tf.keras.layers.Dense(num)(p)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs, p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1000, 90, 1)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1024)              207744    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 7)                 132103    \n",
      "=================================================================\n",
      "Total params: 339,847\n",
      "Trainable params: 339,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Model \n",
    "\n",
    "encoder = build_encoder()\n",
    "classifier = build_classifier(encoder.output_shape[1:],output_shape=7)\n",
    "model = models.define_graph([encoder,classifier],INPUT_SHAPE)\n",
    "\n",
    "### addition for DANN (gradient reverse)\n",
    "# grad_reverse_layer = GradReverseLayer()\n",
    "# dann_domain_discrimination_graph = model_utilis.define_graph([encoder,grad_reverse_layer,discriminator],INPUT_SHAPE)\n",
    "\n",
    "### VGG \n",
    "# vgg_top = create_VGG(8,False)\n",
    "# _,vgg_clf,vgg_discriminator = build_model(8,normalize=False,seperate=True,latent_shape=vgg_top.output_shape[1:])\n",
    "\n",
    "# vgg_model = model_utilis.define_graph([vgg_top,vgg_clf],(1000,90,3))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 7), dtype=float32, numpy=\n",
       "array([[0.14657055, 0.14354338, 0.14357886, 0.14383782, 0.14535202,\n",
       "        0.14078243, 0.13633496],\n",
       "       [0.14619829, 0.14379065, 0.14338136, 0.14329432, 0.1456556 ,\n",
       "        0.14105475, 0.136625  ],\n",
       "       [0.14627661, 0.143331  , 0.14449358, 0.14435977, 0.14477381,\n",
       "        0.14019497, 0.13657022],\n",
       "       [0.14599076, 0.14417191, 0.14326803, 0.14368762, 0.14551394,\n",
       "        0.14126405, 0.13610362],\n",
       "       [0.14665483, 0.14306092, 0.14425969, 0.14385347, 0.14518459,\n",
       "        0.14034711, 0.1366394 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sample: 5,(1000,90,1) --> 5,(7,)\n",
    "\n",
    "model(tf.random.uniform(shape=(5,1000,90,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S1.3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dataset (Yousefi,2017)\n",
    "\n",
    "folderpath = \"./external/yousefi/Dataset/Data\"\n",
    "df = external_dataset.import_dataframe(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetObject EXT\n",
    "\n",
    "dataset_exp1 = external_dataset.DatasetObject(df,cnn=True,sep='residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self dataset EXP1 \n",
    "\n",
    "folderpath1 = \"./data/exp_1\"  # CHANGE THIS IF THE PATH CHANGED\n",
    "df_exp1 = dataset.import_dataframe(folderpath1) # CHANGE THIS IF THE PATH CHANGED\n",
    "# processing step, required\n",
    "df_exp1 = df_exp1.drop([f\"theta_{i}\" for i in range(1,91)], axis=1) \n",
    "print(df_exp1.shape)\n",
    "\n",
    "dataset_exp1 = dataset.DatasetObject(df_exp1,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp1.one_hot(1)\n",
    "ohe_z = dataset_exp1.one_hot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self dataset EXP2 \n",
    "\n",
    "\n",
    "folderpath2 = \"./data/exp_2\" # CHANGE THIS IF THE PATH CHANGED\n",
    "df_exp2 = dataset.import_dataframe(folderpath2)\n",
    "# Preprocessing \n",
    "df_exp2['user'] = df_exp2['user'].map(lambda x: x.split('.')[0]) # processing step, required\n",
    "df_exp2 = df_exp2.iloc[:,2:] # processing step, required\n",
    "print(df_exp2.shape)\n",
    "\n",
    "dataset_exp2 = dataset.DatasetObject(df_exp2,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp2.one_hot(1,ohe_y)\n",
    "ohe_z = dataset_exp2.one_hot(2,ohe_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.concat([df_exp1,df_exp2],axis=0)\n",
    "dataset_exp4 = dataset.DatasetObject(df_,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp4.one_hot(1)\n",
    "ohe_z = dataset_exp4.one_hot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_exp1, df_exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=200)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 1.9150 - accuracy: 0.1913 - val_loss: 1.7918 - val_accuracy: 0.3381\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 1.5762 - accuracy: 0.4310 - val_loss: 1.3566 - val_accuracy: 0.5571\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.1034 - accuracy: 0.6515 - val_loss: 1.0609 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.7563 - accuracy: 0.7593 - val_loss: 0.7562 - val_accuracy: 0.7762\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.4985 - accuracy: 0.8519 - val_loss: 0.8057 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.3176 - accuracy: 0.9128 - val_loss: 0.6735 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 0.1899 - accuracy: 0.9640 - val_loss: 0.6866 - val_accuracy: 0.7714\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.1119 - accuracy: 0.9823 - val_loss: 0.6154 - val_accuracy: 0.8048\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0717 - accuracy: 0.9928 - val_loss: 0.6640 - val_accuracy: 0.7905\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0350 - accuracy: 0.9986 - val_loss: 0.6494 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 0.8190\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8143\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.8143\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8190\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8190\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8238\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8190\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8286\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8286\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8286\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8286\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 9.9493e-04 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 9.2298e-04 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8238\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 8.6021e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8286\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 8.0084e-04 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8286\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 7.5079e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8286\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 7.0276e-04 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 6.6153e-04 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 6.2033e-04 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8381\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 5.8309e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.8286\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 5.5145e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 5.1945e-04 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.8381\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 4.9121e-04 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 4.6673e-04 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.8381\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 4.4332e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8286\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 4.2129e-04 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.8286\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 3.9786e-04 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.8286\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 3.8127e-04 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 3.6003e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8381\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 3.4575e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8286\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 3.3046e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8286\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 3.1541e-04 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.8381\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 3.0021e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 2.8781e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8286\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 2.7585e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8381\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 2.6454e-04 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8429\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 2.5381e-04 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8381\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 2.4205e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 5s 143ms/step - loss: 2.3251e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 2.2320e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8286\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 2.1484e-04 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8429\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 2.0613e-04 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8286\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.9870e-04 - accuracy: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 1.9128e-04 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.8381\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 1.8402e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 1.7778e-04 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.8429\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 1.7113e-04 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 1.6495e-04 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.5940e-04 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.8286\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.5364e-04 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 1.4815e-04 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 1.4292e-04 - accuracy: 1.0000 - val_loss: 0.7777 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 1.3830e-04 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 1.3398e-04 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 1.2956e-04 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 5s 145ms/step - loss: 1.2478e-04 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.2098e-04 - accuracy: 1.0000 - val_loss: 0.7866 - val_accuracy: 0.8286\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 1.1715e-04 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.8429\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.1265e-04 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.8429\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.0901e-04 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.8286\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 5s 141ms/step - loss: 1.0584e-04 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 1.0231e-04 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.8286\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 9.8735e-05 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 9.5218e-05 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8429\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 9.2213e-05 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 8.9153e-05 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 8.6595e-05 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8429\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 8.3774e-05 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 8.1072e-05 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 7.8601e-05 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 7.6121e-05 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.8381\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 7.3771e-05 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 7.1628e-05 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.8381\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 6.9711e-05 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 6.7435e-05 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 6.5478e-05 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.8429\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 6.3620e-05 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 5s 144ms/step - loss: 6.2088e-05 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 5s 143ms/step - loss: 5.9922e-05 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 5.8156e-05 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.8429\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 5.6507e-05 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 5.4973e-05 - accuracy: 1.0000 - val_loss: 0.8197 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "### single\n",
    "train,test = dataset_exp1.query([6])\n",
    "history = model.fit(x=train[0],y=train[1],batch_size=64,epochs=100,verbose=1,validation_data=(test[0],test[1]),callbacks=[callback])\n",
    "\n",
    "### cross validation\n",
    "# model,histories,scores = model_utilis.cross_validation(model,dataset_exp1,batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bed       0.90      0.87      0.88        30\n",
      "        fall       1.00      0.33      0.50        30\n",
      "      pickup       0.86      1.00      0.92        30\n",
      "         run       0.77      1.00      0.87        30\n",
      "     sitdown       0.82      0.93      0.87        30\n",
      "     standup       0.86      0.83      0.85        30\n",
      "        walk       0.76      0.87      0.81        30\n",
      "\n",
      "    accuracy                           0.83       210\n",
      "   macro avg       0.85      0.83      0.82       210\n",
      "weighted avg       0.85      0.83      0.82       210\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict : bed</th>\n",
       "      <th>predict : fall</th>\n",
       "      <th>predict : pickup</th>\n",
       "      <th>predict : run</th>\n",
       "      <th>predict : sitdown</th>\n",
       "      <th>predict : standup</th>\n",
       "      <th>predict : walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual: bed</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: fall</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: pickup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: run</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: sitdown</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: standup</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual: walk</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict : bed  predict : fall  predict : pickup  \\\n",
       "actual: bed                 26               0                 1   \n",
       "actual: fall                 1              10                 4   \n",
       "actual: pickup               0               0                30   \n",
       "actual: run                  0               0                 0   \n",
       "actual: sitdown              0               0                 0   \n",
       "actual: standup              2               0                 0   \n",
       "actual: walk                 0               0                 0   \n",
       "\n",
       "                 predict : run  predict : sitdown  predict : standup  \\\n",
       "actual: bed                  0                  3                  0   \n",
       "actual: fall                 4                  0                  3   \n",
       "actual: pickup               0                  0                  0   \n",
       "actual: run                 30                  0                  0   \n",
       "actual: sitdown              1                 28                  1   \n",
       "actual: standup              0                  3                 25   \n",
       "actual: walk                 4                  0                  0   \n",
       "\n",
       "                 predict : walk  \n",
       "actual: bed                   0  \n",
       "actual: fall                  8  \n",
       "actual: pickup                0  \n",
       "actual: run                   0  \n",
       "actual: sitdown               0  \n",
       "actual: standup               0  \n",
       "actual: walk                 26  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "train,test = dataset_exp1.query([6])\n",
    "cmtx = utils.evaluation(model,test[0],test[1],ohe=dataset_exp1.ohe)\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "model_name = f\"model_{current_time}\"\n",
    "savepath = f'./saved_model/{model_name}.h5'\n",
    "model.save(savepath)\n",
    "print(\"model saved: \",savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx.to_csv(f\"./record/cmtx_{model_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
