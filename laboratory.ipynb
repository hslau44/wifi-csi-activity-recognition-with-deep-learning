{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S 0.0 Set parameter and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler, MinMaxScaler,Normalizer\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset,model_utilis,utils\n",
    "# from external.yousefi import dataset as external_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters \n",
    "INPUT_SHAPE = (1000,90,1) \n",
    "ACTIVATION = None\n",
    "bn_trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function define\n",
    "lrelu = tf.keras.layers.LeakyReLU\n",
    "softmax = tf.keras.layers.Softmax\n",
    "normalization = tfa.layers.InstanceNormalization\n",
    "identity = tf.keras.layers.Lambda(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient reverse layer (Yanin 2015)\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GradReverseLayer, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(label_size,normalize=False,seperate=False,latent_shape=None):\n",
    "    \"\"\"\n",
    "    Shallow Convolutional Neural network model, change architecture here\n",
    "    \n",
    "    Input\n",
    "        label_size (tuple): label size\n",
    "        normalize (bool): add normalization layers \n",
    "        seperate (bool): if True return encoder,classifier and discriminator\n",
    "        latent_shape (None/tuple): return an classifier and discriminator, given seperate == True and latent_shape != None\n",
    "        \n",
    "    \"\"\"\n",
    "    ### element define\n",
    "    disc_input  = tf.keras.layers.Input((1000,90,1))\n",
    "    disc_conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides = (5,5))\n",
    "    disc_conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (3,3))\n",
    "    disc_conv_3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(2,2), strides = (2,2))\n",
    "    disc_flaten = tf.keras.layers.Flatten()\n",
    "    disc_lab_d1 = tf.keras.layers.Dense(128,activation=lrelu())\n",
    "    disc_lab_d2 = tf.keras.layers.Dense(label_size)\n",
    "    disc_dmn_d1 = tf.keras.layers.Dense(128,activation=lrelu())\n",
    "    disc_dmn_d2 = tf.keras.layers.Dense(1) # change here for categorical crossentropy \n",
    "    ### activation\n",
    "    activation_1 = tf.keras.layers.ReLU()\n",
    "    activation_2 = tf.keras.layers.ReLU()\n",
    "    activation_3 = tf.keras.layers.Activation('tanh')\n",
    "    ### pooling \n",
    "    pooling_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    pooling_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    pooling_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,1))\n",
    "    dropout_l = tf.keras.layers.Dropout(0.1)\n",
    "    dropout_d = tf.keras.layers.Dropout(0.1)\n",
    "    ### normalization\n",
    "    disc_norm_c1 = normalization()\n",
    "    disc_norm_c2 = normalization()\n",
    "    \n",
    "    ##### graph define #####\n",
    "    if normalize == True:\n",
    "        x = disc_conv_1(disc_input)\n",
    "        x = disc_norm_c1(x)\n",
    "        x = activation_1(x)\n",
    "        x = pooling_1(x)\n",
    "        x = disc_conv_2(x)\n",
    "        x = disc_norm_c2(x)\n",
    "        x = activation_2(x)\n",
    "        x = pooling_2(x)\n",
    "        x = disc_conv_3(x)\n",
    "        x = activation_3(x)\n",
    "        x = pooling_3(x)\n",
    "    else:   \n",
    "        x = disc_conv_1(disc_input)\n",
    "        #x = disc_norm_c1(x)\n",
    "        x = activation_1(x)\n",
    "        x = pooling_1(x)\n",
    "        x = disc_conv_2(x)\n",
    "        #x = disc_norm_c2(x)\n",
    "        x = activation_2(x)\n",
    "        x = pooling_2(x)\n",
    "        x = disc_conv_3(x)\n",
    "        x = activation_3(x)\n",
    "        x = pooling_3(x)\n",
    "    p = disc_flaten(x)\n",
    "    if seperate == True:\n",
    "        ### encoder\n",
    "        encoder = tf.keras.models.Model(inputs=disc_input, outputs=p)\n",
    "        ### shape\n",
    "        if latent_shape != None:\n",
    "            lab_input = tf.keras.layers.Input(latent_shape)\n",
    "            dmn_input = tf.keras.layers.Input(latent_shape)\n",
    "        else:\n",
    "            lab_input = tf.keras.layers.Input(p.shape[1:])\n",
    "            dmn_input = tf.keras.layers.Input(p.shape[1:])\n",
    "        ### label\n",
    "        x1 = disc_lab_d1(lab_input)\n",
    "        x1 = dropout_l(x1)\n",
    "        o1 = disc_lab_d2(x1)\n",
    "        lab = tf.keras.models.Model(inputs=lab_input, outputs=o1)\n",
    "        ### domain \n",
    "        x2 = disc_dmn_d1(dmn_input)\n",
    "        x2 = dropout_d(x2)\n",
    "        o2 = disc_dmn_d2(x2)\n",
    "        dmn = tf.keras.models.Model(inputs=dmn_input, outputs=o2)\n",
    "        return encoder,lab,dmn\n",
    "    else:\n",
    "        x1 = disc_lab_d1(p)\n",
    "        x1 = dropout_l(x1)\n",
    "        o1 = disc_lab_d2(x1)\n",
    "        x2 = disc_dmn_d1(p)\n",
    "        x2 = dropout_d(x2)\n",
    "        o2 = disc_dmn_d2(x2)\n",
    "        model = tf.keras.models.Model(inputs=disc_input, outputs=[o1,o2])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VGG(num=8,top=True):\n",
    "    base_model = VGG16(include_top=False,input_shape=(1000, 90, 3))\n",
    "    base_model.trainable = False\n",
    "    inputs = tf.keras.layers.Input(shape=(1000, 90, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    p = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if top == True:\n",
    "        p = tf.keras.layers.Dense(128,activation='relu')(p)\n",
    "        outputs = tf.keras.layers.Dense(num)(p)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs, p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1000, 90, 1)]     0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1024)              206848    \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 8)                 132232    \n",
      "=================================================================\n",
      "Total params: 339,080\n",
      "Trainable params: 339,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Model \n",
    "encoder,classifier,discriminator = build_model(8,normalize=False,seperate=True)\n",
    "model = model_utilis.define_graph([encoder,classifier],INPUT_SHAPE)\n",
    "\n",
    "### addition for DANN (gradient reverse)\n",
    "# grad_reverse_layer = GradReverseLayer()\n",
    "# dann_domain_discrimination_graph = model_utilis.define_graph([encoder,grad_reverse_layer,discriminator],INPUT_SHAPE)\n",
    "\n",
    "### VGG \n",
    "# vgg_top = create_VGG(8,False)\n",
    "# _,vgg_clf,vgg_discriminator = build_model(8,normalize=False,seperate=True,latent_shape=vgg_top.output_shape[1:])\n",
    "\n",
    "# vgg_model = model_utilis.define_graph([vgg_top,vgg_clf],(1000,90,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S1.3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dataset (Yousefi,2017)\n",
    "\n",
    "folderpath = \"./external/yousefi/Dataset/Data\"\n",
    "df = external_dataset.import_dataframe(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetObject EXT\n",
    "\n",
    "dataset_exp1 = external_dataset.DatasetObject(df,cnn=True,sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 files.\n",
      "input_user10_bendfwd.csv annotation_user10_bendfwd.csv user10\n",
      "input_user10_kneel.csv annotation_user10_kneel.csv user10\n",
      "input_user10_lie.csv annotation_user10_lie.csv user10\n",
      "input_user10_sit.csv annotation_user10_sit.csv user10\n",
      "input_user10_sitrotate.csv annotation_user10_sitrotate.csv user10\n",
      "input_user10_stand.csv annotation_user10_stand.csv user10\n",
      "input_user10_standrotate.csv annotation_user10_standrotate.csv user10\n",
      "input_user10_walking.csv annotation_user10_walking.csv user10\n",
      "input_user1_bendfwd.csv annotation_user1_bendfwd.csv user1\n",
      "input_user1_kneel.csv annotation_user1_kneel.csv user1\n",
      "input_user1_lie.csv annotation_user1_lie.csv user1\n",
      "input_user1_sit.csv annotation_user1_sit.csv user1\n",
      "input_user1_sitrotate.csv annotation_user1_sitrotate.csv user1\n",
      "input_user1_stand.csv annotation_user1_stand.csv user1\n",
      "input_user1_standrotate.csv annotation_user1_standrotate.csv user1\n",
      "input_user1_walking.csv annotation_user1_walking.csv user1\n",
      "input_user2_bendfwd.csv annotation_user2_bendfwd.csv user2\n",
      "input_user2_kneel.csv annotation_user2_kneel.csv user2\n",
      "input_user2_lie.csv annotation_user2_lie.csv user2\n",
      "input_user2_sit.csv annotation_user2_sit.csv user2\n",
      "input_user2_sitrotate.csv annotation_user2_sitrotate.csv user2\n",
      "input_user2_stand.csv annotation_user2_stand.csv user2\n",
      "input_user2_standrotate.csv annotation_user2_standrotate.csv user2\n",
      "input_user2_walking.csv annotation_user2_walking.csv user2\n",
      "input_user3_bendfwd.csv annotation_user3_bendfwd.csv user3\n",
      "input_user3_kneel.csv annotation_user3_kneel.csv user3\n",
      "input_user3_lie.csv annotation_user3_lie.csv user3\n",
      "input_user3_sit.csv annotation_user3_sit.csv user3\n",
      "input_user3_sitrotate.csv annotation_user3_sitrotate.csv user3\n",
      "input_user3_stand.csv annotation_user3_stand.csv user3\n",
      "input_user3_standrotate.csv annotation_user3_standrotate.csv user3\n",
      "input_user3_walking.csv annotation_user3_walking.csv user3\n",
      "input_user4_bendfwd.csv annotation_user4_bendfwd.csv user4\n",
      "input_user4_kneel.csv annotation_user4_kneel.csv user4\n",
      "input_user4_lie.csv annotation_user4_lie.csv user4\n",
      "input_user4_sit.csv annotation_user4_sit.csv user4\n",
      "input_user4_sitrotate.csv annotation_user4_sitrotate.csv user4\n",
      "input_user4_stand.csv annotation_user4_stand.csv user4\n",
      "input_user4_standrotate.csv annotation_user4_standrotate.csv user4\n",
      "input_user4_walking.csv annotation_user4_walking.csv user4\n",
      "input_user5_bendfwd.csv annotation_user5_bendfwd.csv user5\n",
      "input_user5_kneel.csv annotation_user5_kneel.csv user5\n",
      "input_user5_lie.csv annotation_user5_lie.csv user5\n",
      "input_user5_sit.csv annotation_user5_sit.csv user5\n",
      "input_user5_sitrotate.csv annotation_user5_sitrotate.csv user5\n",
      "input_user5_stand.csv annotation_user5_stand.csv user5\n",
      "input_user5_standrotate.csv annotation_user5_standrotate.csv user5\n",
      "input_user5_walking.csv annotation_user5_walking.csv user5\n",
      "input_user6_bendfwd.csv annotation_user6_bendfwd.csv user6\n",
      "input_user6_kneel.csv annotation_user6_kneel.csv user6\n",
      "input_user6_lie.csv annotation_user6_lie.csv user6\n",
      "input_user6_sit.csv annotation_user6_sit.csv user6\n",
      "input_user6_sitrotate.csv annotation_user6_sitrotate.csv user6\n",
      "input_user6_stand.csv annotation_user6_stand.csv user6\n",
      "input_user6_standrotate.csv annotation_user6_standrotate.csv user6\n",
      "input_user6_walking.csv annotation_user6_walking.csv user6\n",
      "input_user7_bendfwd.csv annotation_user7_bendfwd.csv user7\n",
      "input_user7_kneel.csv annotation_user7_kneel.csv user7\n",
      "input_user7_lie.csv annotation_user7_lie.csv user7\n",
      "input_user7_sit.csv annotation_user7_sit.csv user7\n",
      "input_user7_sitrotate.csv annotation_user7_sitrotate.csv user7\n",
      "input_user7_stand.csv annotation_user7_stand.csv user7\n",
      "input_user7_standrotate.csv annotation_user7_standrotate.csv user7\n",
      "input_user7_walking.csv annotation_user7_walking.csv user7\n",
      "input_user8_bendfwd.csv annotation_user8_bendfwd.csv user8\n",
      "input_user8_kneel.csv annotation_user8_kneel.csv user8\n",
      "input_user8_lie.csv annotation_user8_lie.csv user8\n",
      "input_user8_sit.csv annotation_user8_sit.csv user8\n",
      "input_user8_sitrotate.csv annotation_user8_sitrotate.csv user8\n",
      "input_user8_stand.csv annotation_user8_stand.csv user8\n",
      "input_user8_standrotate.csv annotation_user8_standrotate.csv user8\n",
      "input_user8_walking.csv annotation_user8_walking.csv user8\n",
      "input_user9_bendfwd.csv annotation_user9_bendfwd.csv user9\n",
      "input_user9_kneel.csv annotation_user9_kneel.csv user9\n",
      "input_user9_lie.csv annotation_user9_lie.csv user9\n",
      "input_user9_sit.csv annotation_user9_sit.csv user9\n",
      "input_user9_sitrotate.csv annotation_user9_sitrotate.csv user9\n",
      "input_user9_stand.csv annotation_user9_stand.csv user9\n",
      "input_user9_standrotate.csv annotation_user9_standrotate.csv user9\n",
      "input_user9_walking.csv annotation_user9_walking.csv user9\n",
      "(559920, 92)\n",
      "fit_dataframe\n",
      "user10 done\n",
      "done\n",
      "(112, 1000, 90, 1) (112, 1) (144, 1)\n",
      "fit_dataframe\n",
      "user1 done\n",
      "done\n",
      "(104, 1000, 90, 1) (104, 1) (146, 1)\n",
      "fit_dataframe\n",
      "user2 done\n",
      "done\n",
      "(80, 1000, 90, 1) (80, 1) (142, 1)\n",
      "fit_dataframe\n",
      "user3 done\n",
      "done\n",
      "(88, 1000, 90, 1) (88, 1) (139, 1)\n",
      "fit_dataframe\n",
      "user4 done\n",
      "done\n",
      "(88, 1000, 90, 1) (88, 1) (136, 1)\n",
      "fit_dataframe\n",
      "user5 done\n",
      "done\n",
      "(88, 1000, 90, 1) (88, 1) (136, 1)\n",
      "fit_dataframe\n",
      "user6 done\n",
      "done\n",
      "(104, 1000, 90, 1) (104, 1) (152, 1)\n",
      "fit_dataframe\n",
      "user7 done\n",
      "done\n",
      "(88, 1000, 90, 1) (88, 1) (143, 1)\n",
      "fit_dataframe\n",
      "user8 done\n",
      "done\n",
      "(96, 1000, 90, 1) (96, 1) (144, 1)\n",
      "fit_dataframe\n",
      "user9 done\n",
      "done\n",
      "(96, 1000, 90, 1) (96, 1) (147, 1)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "# Self dataset EXP1 \n",
    "\n",
    "folderpath1 = \"./data/exp_1\"  # CHANGE THIS IF THE PATH CHANGED\n",
    "df_exp1 = dataset.import_dataframe(folderpath1) # CHANGE THIS IF THE PATH CHANGED\n",
    "# processing step, required\n",
    "df_exp1 = df_exp1.drop([f\"theta_{i}\" for i in range(1,91)], axis=1) \n",
    "print(df_exp1.shape)\n",
    "\n",
    "dataset_exp1 = dataset.DatasetObject(df_exp1,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp1.one_hot(1)\n",
    "ohe_z = dataset_exp1.one_hot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self dataset EXP2 \n",
    "\n",
    "\n",
    "folderpath2 = \"./data/exp_2\" # CHANGE THIS IF THE PATH CHANGED\n",
    "df_exp2 = dataset.import_dataframe(folderpath2)\n",
    "# Preprocessing \n",
    "df_exp2['user'] = df_exp2['user'].map(lambda x: x.split('.')[0]) # processing step, required\n",
    "df_exp2 = df_exp2.iloc[:,2:] # processing step, required\n",
    "print(df_exp2.shape)\n",
    "\n",
    "dataset_exp2 = dataset.DatasetObject(df_exp2,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp2.one_hot(1,ohe_y)\n",
    "ohe_z = dataset_exp2.one_hot(2,ohe_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.concat([df_exp1,df_exp2],axis=0)\n",
    "dataset_exp4 = dataset.DatasetObject(df_,cnn=True,stacking=False)\n",
    "ohe_y = dataset_exp4.one_hot(1)\n",
    "ohe_z = dataset_exp4.one_hot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_exp1, df_exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=200)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 1000, 90, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 3.8036 - accuracy: 0.1298 - val_loss: 9.0686 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 3.6468 - accuracy: 0.1119 - val_loss: 2.1017 - val_accuracy: 0.1154\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.1038 - accuracy: 0.1369 - val_loss: 2.1097 - val_accuracy: 0.0962\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0915 - accuracy: 0.1357 - val_loss: 2.0916 - val_accuracy: 0.1058\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0795 - accuracy: 0.1571 - val_loss: 2.0878 - val_accuracy: 0.1058\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0772 - accuracy: 0.1440 - val_loss: 2.0887 - val_accuracy: 0.1923\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0775 - accuracy: 0.1381 - val_loss: 2.0837 - val_accuracy: 0.1442\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 2.0742 - accuracy: 0.1345 - val_loss: 2.0728 - val_accuracy: 0.0673\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0775 - accuracy: 0.1250 - val_loss: 2.0663 - val_accuracy: 0.1346\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0586 - accuracy: 0.1667 - val_loss: 2.0446 - val_accuracy: 0.2115\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0213 - accuracy: 0.2179 - val_loss: 1.9590 - val_accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.1470 - accuracy: 0.1464 - val_loss: 2.1131 - val_accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0888 - accuracy: 0.1262 - val_loss: 2.0719 - val_accuracy: 0.1250\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0680 - accuracy: 0.1357 - val_loss: 2.0730 - val_accuracy: 0.1058\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0589 - accuracy: 0.1583 - val_loss: 2.0639 - val_accuracy: 0.1538\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0441 - accuracy: 0.2250 - val_loss: 2.0585 - val_accuracy: 0.1442\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0195 - accuracy: 0.2512 - val_loss: 2.0083 - val_accuracy: 0.2596\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.9818 - accuracy: 0.2202 - val_loss: 1.9854 - val_accuracy: 0.2788\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.9476 - accuracy: 0.2595 - val_loss: 1.8362 - val_accuracy: 0.2788\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0602 - accuracy: 0.2762 - val_loss: 7.7498 - val_accuracy: 0.2788\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 4.5432 - accuracy: 0.1536 - val_loss: 3.6908 - val_accuracy: 0.1250\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 3.6001 - accuracy: 0.1250 - val_loss: 3.3189 - val_accuracy: 0.1250\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 5.3958 - accuracy: 0.1250 - val_loss: 2.1915 - val_accuracy: 0.1250\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.1213 - accuracy: 0.1298 - val_loss: 2.0871 - val_accuracy: 0.1250\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0784 - accuracy: 0.1440 - val_loss: 2.0871 - val_accuracy: 0.1058\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0822 - accuracy: 0.1262 - val_loss: 2.0744 - val_accuracy: 0.1442\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0799 - accuracy: 0.1286 - val_loss: 2.0843 - val_accuracy: 0.1250\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0776 - accuracy: 0.1286 - val_loss: 2.0701 - val_accuracy: 0.1346\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0752 - accuracy: 0.1381 - val_loss: 2.0891 - val_accuracy: 0.1154\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0727 - accuracy: 0.1536 - val_loss: 2.0886 - val_accuracy: 0.1346\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0715 - accuracy: 0.1464 - val_loss: 2.0742 - val_accuracy: 0.1635\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0681 - accuracy: 0.1595 - val_loss: 2.0728 - val_accuracy: 0.1635\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0688 - accuracy: 0.1714 - val_loss: 2.0752 - val_accuracy: 0.1538\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0656 - accuracy: 0.1583 - val_loss: 2.0703 - val_accuracy: 0.1346\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0635 - accuracy: 0.1655 - val_loss: 2.0746 - val_accuracy: 0.1731\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0613 - accuracy: 0.1821 - val_loss: 2.0705 - val_accuracy: 0.1058\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0569 - accuracy: 0.1869 - val_loss: 2.0553 - val_accuracy: 0.1923\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0515 - accuracy: 0.1893 - val_loss: 2.0422 - val_accuracy: 0.1827\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0479 - accuracy: 0.1798 - val_loss: 2.0455 - val_accuracy: 0.1154\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0441 - accuracy: 0.2071 - val_loss: 2.0539 - val_accuracy: 0.2019\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0409 - accuracy: 0.1940 - val_loss: 2.0369 - val_accuracy: 0.2115\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0356 - accuracy: 0.2095 - val_loss: 2.0394 - val_accuracy: 0.1827\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0279 - accuracy: 0.2155 - val_loss: 2.0253 - val_accuracy: 0.2596\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0128 - accuracy: 0.2488 - val_loss: 2.0110 - val_accuracy: 0.2404\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.0014 - accuracy: 0.2083 - val_loss: 1.9980 - val_accuracy: 0.2115\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.9938 - accuracy: 0.2048 - val_loss: 1.9843 - val_accuracy: 0.2212\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.9741 - accuracy: 0.2274 - val_loss: 1.9849 - val_accuracy: 0.2212\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.9577 - accuracy: 0.2548 - val_loss: 1.9507 - val_accuracy: 0.2308\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.9310 - accuracy: 0.2667 - val_loss: 1.9029 - val_accuracy: 0.3077\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.9039 - accuracy: 0.2429 - val_loss: 1.8803 - val_accuracy: 0.2981\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 1.8553 - accuracy: 0.2702 - val_loss: 1.8234 - val_accuracy: 0.2500\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.7811 - accuracy: 0.2917 - val_loss: 1.7130 - val_accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 2.3025 - accuracy: 0.3048 - val_loss: 11.6286 - val_accuracy: 0.1923\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.1365 - accuracy: 0.1583 - val_loss: 5.3496 - val_accuracy: 0.1250\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 5.2503 - accuracy: 0.1250 - val_loss: 5.1016 - val_accuracy: 0.1250\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 4.9815 - accuracy: 0.1262 - val_loss: 4.8061 - val_accuracy: 0.1250\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 5.0594 - accuracy: 0.1250 - val_loss: 11.7786 - val_accuracy: 0.1250\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 11.4405 - accuracy: 0.1250 - val_loss: 10.3053 - val_accuracy: 0.1250\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 10.2056 - accuracy: 0.1250 - val_loss: 9.1718 - val_accuracy: 0.1250\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 8.5862 - accuracy: 0.1262 - val_loss: 8.3603 - val_accuracy: 0.1250\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2869 - accuracy: 0.1250 - val_loss: 8.1843 - val_accuracy: 0.1250\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.1033 - accuracy: 0.1262 - val_loss: 8.0590 - val_accuracy: 0.1250\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.8097 - accuracy: 0.1238 - val_loss: 8.3690 - val_accuracy: 0.1250\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.0399 - accuracy: 0.1250 - val_loss: 9.1439 - val_accuracy: 0.1154\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.7712 - accuracy: 0.1250 - val_loss: 7.5941 - val_accuracy: 0.1250\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.8096 - accuracy: 0.1262 - val_loss: 7.4391 - val_accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.1934 - accuracy: 0.1262 - val_loss: 7.5941 - val_accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.2531 - accuracy: 0.1238 - val_loss: 7.1292 - val_accuracy: 0.1250\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 8.0590 - accuracy: 0.1262 - val_loss: 7.4391 - val_accuracy: 0.1250\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2701 - accuracy: 0.1238 - val_loss: 9.6089 - val_accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2893 - accuracy: 0.1250 - val_loss: 8.0590 - val_accuracy: 0.1250\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.7328 - accuracy: 0.1250 - val_loss: 8.9889 - val_accuracy: 0.1250\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.9631 - accuracy: 0.1238 - val_loss: 7.7491 - val_accuracy: 0.1250\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.8288 - accuracy: 0.1238 - val_loss: 5.8893 - val_accuracy: 0.1250\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.4258 - accuracy: 0.1250 - val_loss: 8.2140 - val_accuracy: 0.1250\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.3469 - accuracy: 0.1262 - val_loss: 8.0590 - val_accuracy: 0.1250\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.9247 - accuracy: 0.1250 - val_loss: 9.1439 - val_accuracy: 0.1250\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.0399 - accuracy: 0.1250 - val_loss: 7.4391 - val_accuracy: 0.1250\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2701 - accuracy: 0.1250 - val_loss: 7.7491 - val_accuracy: 0.1250\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 7.8480 - accuracy: 0.1250 - val_loss: 8.0590 - val_accuracy: 0.1250\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.6945 - accuracy: 0.1250 - val_loss: 7.9041 - val_accuracy: 0.1250\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.1550 - accuracy: 0.1238 - val_loss: 7.2841 - val_accuracy: 0.1250\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.0015 - accuracy: 0.1250 - val_loss: 7.2841 - val_accuracy: 0.1154\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.3469 - accuracy: 0.1262 - val_loss: 8.3690 - val_accuracy: 0.1250\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.3683 - accuracy: 0.1250 - val_loss: 7.1292 - val_accuracy: 0.1250\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.3299 - accuracy: 0.1238 - val_loss: 7.4391 - val_accuracy: 0.1250\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.4044 - accuracy: 0.1262 - val_loss: 9.1439 - val_accuracy: 0.1250\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2126 - accuracy: 0.1274 - val_loss: 7.2841 - val_accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.2317 - accuracy: 0.1250 - val_loss: 6.5092 - val_accuracy: 0.1250\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 7.9631 - accuracy: 0.1250 - val_loss: 9.2989 - val_accuracy: 0.1250\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.2915 - accuracy: 0.1238 - val_loss: 7.2841 - val_accuracy: 0.1250\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.1358 - accuracy: 0.1250 - val_loss: 7.9041 - val_accuracy: 0.1250\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 8.3277 - accuracy: 0.1262 - val_loss: 9.4539 - val_accuracy: 0.1250\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.6561 - accuracy: 0.1250 - val_loss: 9.1439 - val_accuracy: 0.1250\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.3491 - accuracy: 0.1250 - val_loss: 6.6642 - val_accuracy: 0.1250\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.7904 - accuracy: 0.1262 - val_loss: 8.2140 - val_accuracy: 0.1250\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.9247 - accuracy: 0.1250 - val_loss: 7.9041 - val_accuracy: 0.1250\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.6177 - accuracy: 0.1250 - val_loss: 8.3690 - val_accuracy: 0.1250\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 7.9823 - accuracy: 0.1250 - val_loss: 7.7491 - val_accuracy: 0.1250\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 8.1166 - accuracy: 0.1262 - val_loss: 9.1439 - val_accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "### single\n",
    "train,test = dataset_exp1.query([6])\n",
    "history = model.fit(x=train[0],y=train[1],batch_size=64,epochs=100,verbose=1,validation_data=(test[0],test[1]),callbacks=[callback])\n",
    "\n",
    "### cross validation\n",
    "# model,histories,scores = model_utilis.cross_validation(model,dataset_exp1,batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "train,test = dataset_exp1.query([6])\n",
    "cmtx = utils.evaluation(model,test[0],test[1],ohe=ohe_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "model_name = f\"model_{current_time}\"\n",
    "savepath = f'./saved_model/{model_name}.h5'\n",
    "model.save(savepath)\n",
    "print(\"model saved: \",savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx.to_csv(f\"./record/cmtx_{model_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
